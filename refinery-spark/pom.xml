<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>org.wikimedia.analytics.refinery</groupId>
        <artifactId>refinery</artifactId>
        <version>0.2.31-SNAPSHOT</version>
    </parent>

    <groupId>org.wikimedia.analytics.refinery.spark</groupId>
    <artifactId>refinery-spark</artifactId>
    <name>Wikimedia Analytics Refinery Spark</name>
    <packaging>jar</packaging>

    <dependencies>

        <dependency>
            <groupId>org.wikimedia.analytics.refinery.core</groupId>
            <artifactId>refinery-core</artifactId>
        </dependency>

        <dependency>
            <groupId>org.wikimedia.analytics.refinery.tools</groupId>
            <artifactId>refinery-tools</artifactId>
        </dependency>

        <!--
             adding explicit dep for snappy and netty otherwise
             spark assumes is on the java.library.path
             see: https://github.com/rvs/snappy-java/blob/master/src/main/resources/org/xerial/snappy/SnappyNativeLoader.java#L47
        -->
        <!-- https://mvnrepository.com/artifact/org.xerial.snappy/snappy-java -->
        <dependency>
            <groupId>org.xerial.snappy</groupId>
            <artifactId>snappy-java</artifactId>
            <version>1.1.8.4</version><!-- Note 2024-01-23: 1.1.2.5 is not compatible with Mac M1 -->
             <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <version>4.1.56.Final</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <!-- javax.servlet in hadoop-common is older than the one in spark -->
                    <groupId>javax.servlet</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs
             Explicitly needed to use DataFrameSuiteBase (tests with SparkSession)
        -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <version>${hadoop.version}</version>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <!-- javax.servlet in hadoop-common is older than the one in spark -->
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <!--
                Explicit dependency before any spark related dependency
                to circumvent version mismatch
            -->
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.12</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>

        <!--
            Order is important here !
            The CompressionCodecName class is defined in multiple
            dependencies and the spark-sql one should be used.
        -->

        <!--
        Force commons-lang3 version to prevent a bug in JSON date parsing in Spark
        -->
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_2.12</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.12</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>com.netaporter</groupId>
            <artifactId>scala-uri_2.12</artifactId>
            <version>0.4.16</version>
        </dependency>

        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_2.12</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>com.github.nscala-time</groupId>
            <artifactId>nscala-time_2.12</artifactId>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-avro_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-graphx_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/graphframes/graphframes -->
        <dependency>
            <groupId>graphframes</groupId>
            <artifactId>graphframes</artifactId>
            <version>0.8.1-spark3.0-s_2.12</version>
        </dependency>

        <dependency>
            <groupId>com.holdenkarau</groupId>
            <artifactId>spark-testing-base_2.12</artifactId>
            <version>3.1.1_1.1.0</version>
            <scope>test</scope>
        </dependency>

        <dependency>
          <groupId>org.yaml</groupId>
          <artifactId>snakeyaml</artifactId>
          <version>1.20</version>
        </dependency>

        <dependency>
            <groupId>org.scalamock</groupId>
            <artifactId>scalamock-scalatest-support_2.12</artifactId>
            <version>3.6.0</version>
            <scope>test</scope>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient -->
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
        </dependency>

        <!-- Needed to query Hive instead of Spark for ALTER TABLE in Refine job -->
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-jdbc</artifactId>
            <scope>provided</scope>
        </dependency>

        <!-- Needed to prevent warnings from hive-jdbc at test time -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-annotations</artifactId>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>com.datastax.spark</groupId>
            <artifactId>spark-cassandra-connector_2.12</artifactId>
            <version>3.1.0</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/com.amazon.deequ/deequ -->
        <dependency>
            <groupId>com.amazon.deequ</groupId>
            <artifactId>deequ</artifactId>
            <version>2.0.4-spark-3.1</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.scala-tools</groupId>
                <artifactId>maven-scala-plugin</artifactId>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>

            <plugin>
              <groupId>org.scalatest</groupId>
              <artifactId>scalatest-maven-plugin</artifactId>
              <executions>
                <execution>
                  <id>test</id>
                  <goals>
                    <goal>test</goal>
                  </goals>
                </execution>
              </executions>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
