<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>org.wikimedia.analytics.refinery</groupId>
        <artifactId>refinery</artifactId>
        <version>0.2.45</version>
    </parent>

    <groupId>org.wikimedia.analytics.refinery.job</groupId>
    <artifactId>refinery-job</artifactId>
    <packaging>jar</packaging>
    <name>Wikimedia Analytics Refinery Jobs</name>

    <dependencies>
        <?SORTPOM IGNORE?>
        <dependency>
            <groupId>org.wikimedia.analytics.refinery.core</groupId>
            <artifactId>refinery-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikimedia.analytics.refinery.hive</groupId>
            <artifactId>refinery-hive</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikimedia.analytics.refinery.spark</groupId>
            <artifactId>refinery-spark</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikimedia.analytics.refinery.tools</groupId>
            <artifactId>refinery-tools</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikimedia</groupId>
            <artifactId>eventutilities-shaded</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikimedia</groupId>
            <artifactId>eventutilities-spark</artifactId>
        </dependency>
        <dependency>
            <!--
                 adding explicit dep for snappy and netty otherwise
                 spark assumes is on the java.library.path
                 see: https://github.com/rvs/snappy-java/blob/master/src/main/resources/org/xerial/snappy/SnappyNativeLoader.java#L47
            -->
            <groupId>org.xerial.snappy</groupId>
            <artifactId>snappy-java</artifactId>
             <scope>test</scope>
        </dependency>
        <dependency>
            <!-- Explicitely providing netty for test -->
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <!-- javax.servlet in hadoop-common is older than the one in spark -->
                    <groupId>javax.servlet</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <!-- Explicitly needed to use DataFrameSuiteBase (tests with SparkSession) -->
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <!-- javax.servlet in hadoop-common is older than the one in spark -->
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <!--
                Explicit dependency before any spark related dependency
                to circumvent version mismatch
            -->
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.netaporter</groupId>
            <artifactId>scala-uri_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>com.twitter</groupId>
            <artifactId>algebird-core_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.github.scopt</groupId>
            <artifactId>scopt_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.compat.version}</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.github.nscala-time</groupId>
            <artifactId>nscala-time_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-avro_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-graphx_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>graphframes</groupId>
            <artifactId>graphframes</artifactId>
        </dependency>
        <dependency>
            <groupId>com.holdenkarau</groupId>
            <artifactId>spark-testing-base_${scala.compat.version}</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
          <groupId>org.yaml</groupId>
          <artifactId>snakeyaml</artifactId>
        </dependency>
        <dependency>
            <groupId>org.scalamock</groupId>
            <artifactId>scalamock-scalatest-support_${scala.compat.version}</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpcore</artifactId>
        </dependency>
        <dependency>
            <!-- Force commons-lang3 version to prevent a bug in JSON date parsing in Spark -->
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-mllib_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>com.criteo</groupId>
            <artifactId>rsvd</artifactId>
            <exclusions>
                <!--
                  Excluded from here as this dependency is a snapshot
                  from sunset https://bintray.com/
                  Adding the actual release of the version just after
                 -->
                <exclusion>
                    <groupId>commons-codec</groupId>
                    <artifactId>commons-codec</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <!-- Added to fix failing snapshot dependency from above -->
            <groupId>commons-codec</groupId>
            <artifactId>commons-codec</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive-thriftserver_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-cli</artifactId>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.eclipse.jetty.orbit</groupId>
                    <artifactId>javax.servlet</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>com.amazon.deequ</groupId>
            <artifactId>deequ</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.iceberg</groupId>
            <artifactId>iceberg-spark-runtime-3.1_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <?SORTPOM RESUME?>
    </dependencies>

    <build>
        <pluginManagement>
            <plugins>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-enforcer-plugin</artifactId>
                    <executions>
                        <execution>
                            <id>enforce-no-package-cycles</id>
                            <!-- disable enforcer as this project has package cyclic dependencies -->
                            <phase>none</phase>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                    <!-- Too many violations at the moment -->
                    <!-- TODO: re-enable once violations are fixed -->
                    <groupId>org.basepom.maven</groupId>
                    <artifactId>duplicate-finder-maven-plugin</artifactId>
                    <executions>
                        <execution>
                            <id>duplicate-classes-check</id>
                            <phase>none</phase>
                        </execution>
                    </executions>
                </plugin>
            </plugins>
        </pluginManagement>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
            </plugin>

            <plugin>
                <groupId>org.scalatest</groupId>
                <artifactId>scalatest-maven-plugin</artifactId>
                <configuration>
                    <systemProperties>
                        <maxmind.database.country>${project.build.testOutputDirectory}/GeoIP2-Country-Test.mmdb</maxmind.database.country>
                        <maxmind.database.city>${project.build.testOutputDirectory}/GeoIP2-City-Test.mmdb</maxmind.database.city>
                        <maxmind.database.isp>${project.build.testOutputDirectory}/GeoIP2-ISP-Test.mmdb</maxmind.database.isp>
                    </systemProperties>
                    <filereports>WDF TestSuite.txt</filereports>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
